{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "<h1><center><ins>Exercise Sheet 3</ins></center></h1>\n",
    "<h2><center>Numerical Methods <br><br>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import exp\n",
    "import math \n",
    "from scipy.linalg import lu, lu_solve, lu_factor\n",
    "from scipy.optimize import root as solve_root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Root finding algorithms\n",
    "\n",
    "**(A)** Implement the *bisection*, *secant*, *false position* and *Newton-Raphson* root finding methods, by coding your own version of these algorithms. Make sure to test your codes, checking that indeed they are able to find the root of a function (to do this, you can for example pick an analytic function that allows you test the codes and for which you can compute the roots analytically).\n",
    "\n",
    "**(B)** Use your implementation of the 4 root finding methods (from part **A**) to compute the root of the function:\n",
    "\n",
    "$$f(x) = e^x - 1 - x - \\frac{x^2}{2}$$\n",
    "\n",
    "in the interval $x\\in[-1,2]$. For each method, print out the position of the root and the number of iterations needed to reach it.\n",
    "\n",
    "**(C)** Discuss your results, commenting how the methods compare to one another. Which one is the fastest/slowest? Why? What is the impact of the points you selected to start your iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_methode(f, x_start, x_end, tol=1e-6, max_iter=100): # tol: tolerance of how close to 0 \n",
    "    # Check for sign, if root is inside intervall\n",
    "    if f(x_start) * f(x_end) > 0:\n",
    "        raise ValueError(\"f(x_start) and f(x_end) need to be chosen different.\")\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        x_m = (x_start + x_end) / 2   # find center point \n",
    "        f_m = f(x_m)\n",
    "\n",
    "        # check, if value f(x_m)=0 or is close enough to 0 (tol)\n",
    "        if abs(f_m) < tol or (x_end - x_start) / 2 < tol:\n",
    "            return x_m, i+1\n",
    "\n",
    "        # find the next intervall, in which the root is \n",
    "        if f(x_start) * f_m < 0:\n",
    "            x_end = x_m\n",
    "        else:\n",
    "            x_start = x_m\n",
    "\n",
    "    # when iterated until max_iter, returns the last calculated value \n",
    "    return (x_start + x_end) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  2.0\n",
      "f(root) = 0.0\n"
     ]
    }
   ],
   "source": [
    "# example function \n",
    "def f(x):\n",
    "    return pow(x, 2) - 4\n",
    "\n",
    "# Initial gueses 1 and 3 \n",
    "root, iterations = bisection_methode(f, 1, 3)\n",
    "print(\"root: \", root)\n",
    "print(\"f(root) =\", f(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant_methode(f, x0, x1, tol=1e-6, max_iter=100): \n",
    "    for i in range(max_iter):\n",
    "        f_x0 = f(x0)\n",
    "        f_x1 = f(x1)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if f_x1 - f_x0 == 0:\n",
    "            raise ValueError(\"Division by zero encountered in secant method.\")\n",
    "\n",
    "        # Compute the next approximation\n",
    "        x2 = x1 - f_x1 * (x1 - x0) / (f_x1 - f_x0)\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(x2 - x1) < tol:\n",
    "            return x2, i + 1\n",
    "\n",
    "        # Update points\n",
    "        x0, x1 = x1, x2\n",
    "\n",
    "    raise ValueError(\"Secant method did not converge within the maximum number of iterations.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  2.0000000000004996\n",
      "f(root) = 1.9984014443252818e-12\n"
     ]
    }
   ],
   "source": [
    "# example function \n",
    "def f(x):\n",
    "    return pow(x, 2) - 4\n",
    "\n",
    "# Initial guesses 1 and 3 \n",
    "root, iterations = secant_methode(f, 1, 3)\n",
    "print(\"root: \", root)\n",
    "print(\"f(root) =\", f(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_position(f, a, b, tol=1e-6, max_iter=100):\n",
    "\n",
    "    f_a = f(a)\n",
    "    f_b = f(b)\n",
    "\n",
    "    # Check that the root is bracketed\n",
    "    if f_a * f_b > 0:\n",
    "        raise ValueError(\"f(a) and f(b) must have opposite signs.\")\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Compute the intersection point (linear interpolation)\n",
    "        c = b - f_b * (b - a) / (f_b - f_a)\n",
    "        f_c = f(c)\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(f_c) < tol or abs(b - a) < tol:\n",
    "            return c, i + 1\n",
    "\n",
    "        # Decide which side to replace\n",
    "        if f_a * f_c < 0:\n",
    "            b = c\n",
    "            f_b = f_c\n",
    "        else:\n",
    "            a = c\n",
    "            f_a = f_c\n",
    "\n",
    "    raise ValueError(\"False position method did not converge within the maximum number of iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  2.0000000000004996\n",
      "f(root) = 1.9984014443252818e-12\n"
     ]
    }
   ],
   "source": [
    "# example function \n",
    "def f(x):\n",
    "    return pow(x, 2) - 4\n",
    "\n",
    "# Initial guesses 1 and 3 \n",
    "root, iterations = secant_methode(f, 1, 3)\n",
    "print(\"root: \", root)\n",
    "print(\"f(root) =\", f(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f, df, x0, tol=1e-6, max_iter=100):\n",
    "    for i in range(max_iter):\n",
    "        f_x0 = f(x0)\n",
    "        df_x0 = df(x0)\n",
    "\n",
    "        # Prevent division by zero\n",
    "        if df_x0 == 0:\n",
    "            raise ValueError(\"Derivative is zero. Newton-Raphson method fails.\")\n",
    "\n",
    "        # Update step\n",
    "        x1 = x0 - f_x0 / df_x0\n",
    "\n",
    "        # Check for convergence\n",
    "        if abs(x1 - x0) < tol:\n",
    "            return x1, i + 1\n",
    "\n",
    "        x0 = x1\n",
    "\n",
    "    raise ValueError(\"Newton-Raphson method did not converge within the maximum number of iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:  2.0000000000004996\n",
      "f(root) = 1.9984014443252818e-12\n"
     ]
    }
   ],
   "source": [
    "# example function \n",
    "def f(x):\n",
    "    return pow(x, 2) - 4\n",
    "\n",
    "# Initial guesses 1 and 3 \n",
    "root, iterations = secant_methode(f, 1, 3)\n",
    "print(\"root: \", root)\n",
    "print(\"f(root) =\", f(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Finding Comparison for f(x) = e^x - 1 - x - x^2/2\n",
      "Interval: [-1, 2]\n",
      "\n",
      "Bisection:       root = -0.01562500, iterations = 6\n",
      "False Position:  error -> False position method did not converge within the maximum number of iterations.\n",
      "Secant:          root = -0.00000293, iterations = 45\n",
      "Newton-Raphson:  root = -0.00000305, iterations = 43\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return math.exp(x) - 1 - x - (x**2) / 2\n",
    "\n",
    "def df(x):\n",
    "    return math.exp(x) - 1 - x\n",
    "\n",
    "a, b = -1, 2\n",
    "\n",
    "print(\"Root Finding Comparison for f(x) = e^x - 1 - x - x^2/2\")\n",
    "print(\"Interval: [-1, 2]\\n\")\n",
    "\n",
    "try:\n",
    "    root, it = bisection_methode(f, a, b)\n",
    "    print(f\"Bisection:       root = {root:.8f}, iterations = {it}\")\n",
    "except Exception as e:\n",
    "    print(\"Bisection:       error ->\", e)\n",
    "\n",
    "try:\n",
    "    root, it = false_position(f, a, b)\n",
    "    print(f\"False Position:  root = {root:.8f}, iterations = {it}\")\n",
    "except Exception as e:\n",
    "    print(\"False Position:  error ->\", e)\n",
    "\n",
    "try:\n",
    "    root, it = secant_methode(f, a, b)\n",
    "    print(f\"Secant:          root = {root:.8f}, iterations = {it}\")\n",
    "except Exception as e:\n",
    "    print(\"Secant:          error ->\", e)\n",
    "\n",
    "try:\n",
    "    root, it = newton_raphson(f, df, x0=1)\n",
    "    print(f\"Newton-Raphson:  root = {root:.8f}, iterations = {it}\")\n",
    "except Exception as e:\n",
    "    print(\"Newton-Raphson:  error ->\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastest method is the bisection method, followed by the Newton-Raphson and the secant method. The false position method failed in this case. This is because of a triple root at 0, which makes the function very flat near the root. Because of that, the Newton–Raphson and Secant methods, which normally converge very rapidly, became slow and required many iterations. The bisection method is generally slower, but works more reliable here, because it does not depend on the derivative. The False Position method failed to converge because its bracketing endpoint became fixed due to the flatness of f(x). The results show that for multiple roots, derivative-based and interpolation methods can lose efficiency, while bracketing methods remain robust. The choice for the initial guesses is fine for bracketing methods, but slope-based methods (secant and Newton-Raphson) can have problems: Starting too far from the root when the derivative is small leads to very slow progress. Because the slope near 0 is almost flat, they take many iterations. \n",
    "In order to fix these problems, one can for example start with the bisection method, and as soon as it gets close enough, the method can be change to Newton-Raphson. For the false-position method the illinois modification can be used, in order to prevent endpoint stalling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Sets of linear equations\n",
    "\n",
    "Determine the solution to the following set of linear equations:\n",
    "\n",
    "$$ \n",
    "\\begin{cases}\n",
    "5 x_1 + 3 x_2 &= 15 \\\\\n",
    "x_1 - 4 x_2 &= -2 \\ ,\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $x_1$ and $x_2$ are the variables of interest.\n",
    "\n",
    "**(A)** Formulate the problem by using the matrix representation, as we saw in class, clearly defining the coefficient matrix and the vector of right-hand-side values.\n",
    "\n",
    "**(B)** Using the appropriate built-in python functions, carry out the LU decomposition of the coefficient matrix, and print out the L and U matrices separately. Solve the set of equations and check that the solution is indeed valid.\n",
    "\n",
    "**(C)** What is the solution to the following set of equations? \n",
    "\n",
    "$$ \n",
    "\\begin{cases}\n",
    "x_1 - 4 x_2 &= 3 \\\\\n",
    "5 x_1 + 3 x_2 &= -7\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Print out the solution, and motivate the steps you took to solve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 = 2.3478\n",
      "x2 = 1.0870\n"
     ]
    }
   ],
   "source": [
    "# coefficient matrix \n",
    "A = np.array([\n",
    "    [5, 3],\n",
    "    [1, -4]\n",
    "])\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([15, -2])\n",
    "\n",
    "# Solve for x (x1 and x2)\n",
    "x = np.linalg.solve(A, b)\n",
    "\n",
    "print(f\"x1 = {x[0]:.4f}\")\n",
    "print(f\"x2 = {x[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 5.  3.]\n",
      " [ 1. -4.]]\n",
      "\n",
      "Lower triangular matrix L:\n",
      "[[1.  0. ]\n",
      " [0.2 1. ]]\n",
      "\n",
      "Upper triangular matrix U:\n",
      "[[ 5.   3. ]\n",
      " [ 0.  -4.6]]\n",
      "\n",
      "Permutation matrix P:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "\n",
      "Solution:\n",
      "x1 = 2.3478\n",
      "x2 = 1.0870\n"
     ]
    }
   ],
   "source": [
    "# Coefficient matrix A\n",
    "A = np.array([\n",
    "    [5, 3],\n",
    "    [1, -4]\n",
    "], dtype=float)\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([15, -2], dtype=float)\n",
    "\n",
    "# The function `lu` returns P, L, U\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nLower triangular matrix L:\")\n",
    "print(L)\n",
    "print(\"\\nUpper triangular matrix U:\")\n",
    "print(U)\n",
    "print(\"\\nPermutation matrix P:\")\n",
    "print(P)\n",
    "\n",
    "# We can either use lu_factor and lu_solve for direct solution:\n",
    "lu_piv = lu_factor(A)\n",
    "x = lu_solve(lu_piv, b)\n",
    "\n",
    "print(\"\\nSolution:\")\n",
    "print(f\"x1 = {x[0]:.4f}\")\n",
    "print(f\"x2 = {x[1]:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution to the system:\n",
      "x1 = -0.826087\n",
      "x2 = -0.956522\n",
      "Verification (A*x):  [ 3. -7.]\n",
      "Should equal b = [ 3. -7.]\n"
     ]
    }
   ],
   "source": [
    "# Coefficient matrix A\n",
    "A = np.array([\n",
    "    [1, -4],\n",
    "    [5, 3]\n",
    "], dtype=float)\n",
    "\n",
    "# Right-hand side vector b\n",
    "b = np.array([3, -7], dtype=float)\n",
    "\n",
    "# Solve the linear system A * x = b\n",
    "x = np.linalg.solve(A, b)\n",
    "\n",
    "# Print the results\n",
    "print(\"Solution to the system:\")\n",
    "print(f\"x1 = {x[0]:.6f}\")\n",
    "print(f\"x2 = {x[1]:.6f}\")\n",
    "\n",
    "# Verify by plugging back into the equations\n",
    "check = np.dot(A, x)\n",
    "print(\"Verification (A*x): \", check)\n",
    "print(\"Should equal b =\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Velocity dispersion estimation\n",
    "\n",
    "The file ``omega_Cen_Sollima2009.txt`` contains a collection of measurements of line-of-sight velocities of stars in the Galactic globular cluster $\\omega$ Cen (NGC 5139). The first column in the file contains the values of the velocities (in km/s), and the second column the values of the associated measurement errors (also in km/s). These data are taken from [Sollima et al. (2009)](https://ui.adsabs.harvard.edu/abs/2009MNRAS.396.2183S/abstract).\n",
    "\n",
    "We want to determine the mean velocity $\\bar{v}$ and velocity dispersion $\\sigma$ of these stars, and we do this by using a maximum likelihood estimator, following the procedure described by [Pryor and Meylan (1993)](https://ui.adsabs.harvard.edu/abs/1993ASPC...50..357P/abstract).\n",
    "\n",
    "We start by assuming that each velocity measurement $v_i$ ($i = 1,2,...,N$), with associated error $\\delta_{{\\rm v},i}$, is drawn from the normal distribution:\n",
    "\n",
    "$$ f(v_i) = \\frac{1}{\\sqrt{2 \\pi (\\sigma^2 + \\delta_{{\\rm v},i}^2)}} \\exp\\left[ - \\frac{(v_i - \\bar{v})^2}{2(\\sigma^2 + \\delta_{{\\rm v},i}^2)} \\right] $$ \n",
    "\n",
    "Standard techniques for forming the likelihood of a set of $N$ velocities and finding its maximum lead to the following two equations:\n",
    "\n",
    "$$\\sum_{i = 1}^{N}  \\frac{v_i}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} - \\bar{v} \\sum_{i = 1}^{N}  \\frac{1}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} = 0$$\n",
    "\n",
    "$$\\sum_{i = 1}^{N}  \\frac{(v_i - \\bar{v})^2}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)^2} - \\sum_{i = 1}^{N}  \\frac{1}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} = 0$$\n",
    "\n",
    "These equations must be solved numerically to obtain $\\bar{v}$ and $\\sigma$.\n",
    "\n",
    "**(A)** Discuss what type of problem this is, and list the possible ways (those we have seen in class, of course!) to solve it numerically with built-in python functions.\n",
    "\n",
    "**(B)** Solve the equations above to obtain the values of the mean velocity $\\bar{v}$ and velocity dispersion $\\sigma$. To do this, use **all** the python built-in functions we discussed in class, and compare the results you obtain. Print out the solutions you get, and verify that they are indeed solutions of the above equations.\n",
    "\n",
    "**(C)** Explore the input and output of the python built-in functions. Pay particular attention to the values you provide as initial guesses to compute the solution: which values break the algorithm? Which algorithm appears to be more stable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a system of two nonlinear equations with two unknowns mean velocity and intrinsic velocity dispersion. It is a maximum likelihood estimation and it needs an iterative numerical solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omega Cen Velocity Dispersion Estimation (MLE)\n",
      "Method          v̄ (km/s)     σ (km/s)   Iterations\n",
      "---------------------------------------------\n",
      "bisection         234.145        9.900           24\n",
      "false             234.144       49.999          100\n",
      "secant       error -> Secant method did not converge within the maximum number of iterations.\n",
      "newton            234.145        9.900            3\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"omega_Cen_Sollima2009.txt\")\n",
    "v = data[:, 0]     # velocities (km/s)\n",
    "dv = data[:, 1]    # measurement errors (km/s)\n",
    "\n",
    "# define 2 equations \n",
    "def equation1(vbar, sigma):\n",
    "    return np.sum(v / (sigma**2 + dv**2)) - vbar * np.sum(1 / (sigma**2 + dv**2))\n",
    "\n",
    "def equation2(vbar, sigma):\n",
    "    return np.sum((v - vbar)**2 / (sigma**2 + dv**2)**2) - np.sum(1 / (sigma**2 + dv**2))\n",
    "\n",
    "# root finding methods \n",
    "# solve MLE system \n",
    "# First, solve equation 1 for vbar given sigma\n",
    "# Then plug result into eqation 2 to find sigma iteratively \n",
    "\n",
    "def find_vbar(sigma):\n",
    "    f = lambda vbar: equation1(vbar, sigma)\n",
    "    df = lambda vbar: -np.sum(1 / (sigma**2 + dv**2))\n",
    "    # Use Newton–Raphson (since equation 1 is linear in vbar)\n",
    "    vbar, _ = newton_raphson(f, df, np.mean(v))\n",
    "    return vbar\n",
    "\n",
    "def solve_sigma(method=\"bisection\"):\n",
    "    f_sigma = lambda sigma: equation2(find_vbar(sigma), sigma)\n",
    "    if method == \"bisection\":\n",
    "        return bisection_methode(f_sigma, 0.1, 50)\n",
    "    elif method == \"false\":\n",
    "        return false_position(f_sigma, 0.1, 50)\n",
    "    elif method == \"secant\":\n",
    "        return secant_methode(f_sigma, 5, 15)\n",
    "    elif method == \"newton\":\n",
    "        # derivative of equation 2 wrt sigma (numerical)\n",
    "        def df_sigma(s):\n",
    "            h = 1e-3\n",
    "            return (f_sigma(s + h) - f_sigma(s - h)) / (2 * h)\n",
    "        return newton_raphson(f_sigma, df_sigma, 10)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method.\")\n",
    "\n",
    "# Run all methods \n",
    "methods = [\"bisection\", \"false\", \"secant\", \"newton\"]\n",
    "\n",
    "print(\"omega Cen Velocity Dispersion Estimation (MLE)\")\n",
    "print(f\"{'Method':<12} {'v̄ (km/s)':>12} {'σ (km/s)':>12} {'Iterations':>12}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for m in methods:\n",
    "    try:\n",
    "        sigma, it = solve_sigma(m)\n",
    "        vbar = find_vbar(sigma)\n",
    "        print(f\"{m:<12} {vbar:12.3f} {sigma:12.3f} {it:12d}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{m:<12} error -> {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisection: Most stable; always converges as long as you choose two endpoints that bracket the root (sign change).\n",
    "\n",
    "False Position: Also stable, but can decay if the function is strongly curved.\n",
    "\n",
    "Secant: Efficient but can diverge when starting far from the solution or if the slope is very small.\n",
    "\n",
    "Newton–Raphson: Extremely fast if the initial guess is close, but very sensitive. A poor guess can send it far away or cause division by zero (derivative ~ 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Likelihood Estimates for omega Cen:\n",
      "Mean velocity (v̄): 234.145 km/s\n",
      "Velocity dispersion (σ): 9.900 km/s\n",
      "Converged: True\n",
      "Message: The solution converged.\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"omega_Cen_Sollima2009.txt\")\n",
    "v = data[:, 0]       # velocities\n",
    "dv = data[:, 1]      # measurement errors\n",
    "\n",
    "# Define system of nonlinear equations \n",
    "def equations(vars):\n",
    "    vbar, sigma = vars\n",
    "    if sigma <= 0:\n",
    "        return [1e10, 1e10]\n",
    "    eq1 = np.sum(v / (sigma**2 + dv**2)) - vbar * np.sum(1 / (sigma**2 + dv**2))\n",
    "    eq2 = np.sum((v - vbar)**2 / (sigma**2 + dv**2)**2) - np.sum(1 / (sigma**2 + dv**2))\n",
    "    return [eq1, eq2]\n",
    "\n",
    "# Initial guesses \n",
    "vbar_guess = np.mean(v)\n",
    "sigma_guess = np.std(v)\n",
    "\n",
    "# Solve system \n",
    "solution = solve_root(equations, [vbar_guess, sigma_guess])\n",
    "\n",
    "vbar_sol, sigma_sol = solution.x\n",
    "print(\"Maximum Likelihood Estimates for omega Cen:\")\n",
    "print(f\"Mean velocity (v̄): {vbar_sol:.3f} km/s\")\n",
    "print(f\"Velocity dispersion (σ): {sigma_sol:.3f} km/s\")\n",
    "print(f\"Converged: {solution.success}\")\n",
    "print(f\"Message: {solution.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
